{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7876394-c795-49cb-8ec7-dea4a783e0bf",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.9\n",
      "Package                       Version\n",
      "----------------------------- -----------\n",
      "absl-py                       1.4.0\n",
      "aiofiles                      22.1.0\n",
      "aiosqlite                     0.18.0\n",
      "alembic                       1.9.4\n",
      "altair                        4.2.2\n",
      "anyio                         3.6.2\n",
      "appdirs                       1.4.4\n",
      "argon2-cffi                   21.3.0\n",
      "argon2-cffi-bindings          21.2.0\n",
      "asttokens                     2.2.1\n",
      "astunparse                    1.6.3\n",
      "async-generator               1.10\n",
      "attrs                         22.2.0\n",
      "Babel                         2.11.0\n",
      "backcall                      0.2.0\n",
      "backports.functools-lru-cache 1.6.4\n",
      "beautifulsoup4                4.11.2\n",
      "biopandas                     0.4.1\n",
      "biopython                     1.81\n",
      "bleach                        6.0.0\n",
      "blinker                       1.5\n",
      "bokeh                         2.4.3\n",
      "Bottleneck                    1.3.6\n",
      "brotlipy                      0.7.0\n",
      "cached-property               1.5.2\n",
      "cachetools                    5.3.1\n",
      "catboost                      1.2\n",
      "certifi                       2022.12.7\n",
      "certipy                       0.1.3\n",
      "cffi                          1.15.1\n",
      "charset-normalizer            2.1.1\n",
      "click                         8.1.3\n",
      "cloudpickle                   2.2.1\n",
      "cmake                         3.26.4\n",
      "colorama                      0.4.6\n",
      "comm                          0.1.2\n",
      "conda                         23.1.0\n",
      "conda-package-handling        2.0.2\n",
      "conda_package_streaming       0.7.0\n",
      "contourpy                     1.0.7\n",
      "cryptography                  39.0.1\n",
      "cycler                        0.11.0\n",
      "Cython                        0.29.33\n",
      "cytoolz                       0.12.0\n",
      "dask                          2023.2.1\n",
      "debugpy                       1.6.6\n",
      "decorator                     5.1.1\n",
      "defusedxml                    0.7.1\n",
      "dill                          0.3.6\n",
      "distributed                   2023.2.1\n",
      "emojis                        0.7.0\n",
      "entrypoints                   0.4\n",
      "et-xmlfile                    1.1.0\n",
      "executing                     1.2.0\n",
      "fastjsonschema                2.16.3\n",
      "fasttext                      0.9.2\n",
      "filelock                      3.12.2\n",
      "flatbuffers                   23.5.26\n",
      "flit_core                     3.8.0\n",
      "fonttools                     4.38.0\n",
      "fsspec                        2023.1.0\n",
      "gast                          0.4.0\n",
      "gmpy2                         2.1.2\n",
      "google-auth                   2.20.0\n",
      "google-auth-oauthlib          1.0.0\n",
      "google-pasta                  0.2.0\n",
      "graphviz                      0.20.1\n",
      "greenlet                      2.0.2\n",
      "grpcio                        1.54.2\n",
      "h5py                          3.8.0\n",
      "HeapDict                      1.0.1\n",
      "idna                          3.4\n",
      "imagecodecs                   2023.1.23\n",
      "imageio                       2.25.1\n",
      "imbalanced-learn              0.10.1\n",
      "importlib-metadata            6.0.0\n",
      "importlib-resources           5.12.0\n",
      "ipykernel                     6.21.2\n",
      "ipympl                        0.9.3\n",
      "ipython                       8.10.0\n",
      "ipython-genutils              0.2.0\n",
      "ipywidgets                    8.0.4\n",
      "jax                           0.4.12\n",
      "jedi                          0.18.2\n",
      "Jinja2                        3.1.2\n",
      "joblib                        1.2.0\n",
      "json5                         0.9.5\n",
      "jsonschema                    4.17.3\n",
      "jupyter_client                8.0.3\n",
      "jupyter_core                  5.2.0\n",
      "jupyter-events                0.6.3\n",
      "jupyter_server                2.3.0\n",
      "jupyter_server_fileid         0.8.0\n",
      "jupyter_server_terminals      0.4.4\n",
      "jupyter_server_ydoc           0.6.1\n",
      "jupyter-telemetry             0.1.0\n",
      "jupyter-ydoc                  0.2.2\n",
      "jupyterhub                    3.1.1\n",
      "jupyterlab                    3.6.1\n",
      "jupyterlab-pygments           0.2.2\n",
      "jupyterlab_server             2.19.0\n",
      "jupyterlab-widgets            3.0.5\n",
      "keras                         2.12.0\n",
      "kiwisolver                    1.4.4\n",
      "libclang                      16.0.0\n",
      "libmambapy                    1.3.1\n",
      "lightgbm                      3.3.5\n",
      "lit                           16.0.6\n",
      "llvmlite                      0.39.1\n",
      "locket                        1.0.0\n",
      "lz4                           4.3.2\n",
      "Mako                          1.2.4\n",
      "mamba                         1.3.1\n",
      "Markdown                      3.4.3\n",
      "MarkupSafe                    2.1.2\n",
      "matplotlib                    3.7.0\n",
      "matplotlib-inline             0.1.6\n",
      "matplotlib-venn               0.11.9\n",
      "mistune                       2.0.5\n",
      "ml-dtypes                     0.2.0\n",
      "mpmath                        1.2.1\n",
      "msgpack                       1.0.4\n",
      "munkres                       1.1.4\n",
      "nbclassic                     0.5.2\n",
      "nbclient                      0.7.2\n",
      "nbconvert                     7.2.9\n",
      "nbformat                      5.7.3\n",
      "nest-asyncio                  1.5.6\n",
      "networkx                      3.0\n",
      "notebook                      6.5.2\n",
      "notebook_shim                 0.2.2\n",
      "numba                         0.56.4\n",
      "numexpr                       2.8.3\n",
      "numpy                         1.23.5\n",
      "nvidia-cublas-cu11            11.10.3.66\n",
      "nvidia-cuda-cupti-cu11        11.7.101\n",
      "nvidia-cuda-nvrtc-cu11        11.7.99\n",
      "nvidia-cuda-runtime-cu11      11.7.99\n",
      "nvidia-cudnn-cu11             8.5.0.96\n",
      "nvidia-cufft-cu11             10.9.0.58\n",
      "nvidia-curand-cu11            10.2.10.91\n",
      "nvidia-cusolver-cu11          11.4.0.1\n",
      "nvidia-cusparse-cu11          11.7.4.91\n",
      "nvidia-nccl-cu11              2.14.3\n",
      "nvidia-nvtx-cu11              11.7.91\n",
      "oauthlib                      3.2.2\n",
      "openpyxl                      3.1.1\n",
      "opt-einsum                    3.3.0\n",
      "packaging                     23.0\n",
      "pamela                        1.0.0\n",
      "pandas                        1.5.3\n",
      "pandocfilters                 1.5.0\n",
      "parso                         0.8.3\n",
      "partd                         1.3.0\n",
      "patsy                         0.5.3\n",
      "pexpect                       4.8.0\n",
      "pickleshare                   0.7.5\n",
      "Pillow                        9.4.0\n",
      "pip                           23.0.1\n",
      "pkgutil_resolve_name          1.3.10\n",
      "platformdirs                  3.0.0\n",
      "plotly                        5.15.0\n",
      "pluggy                        1.0.0\n",
      "pooch                         1.6.0\n",
      "prometheus-client             0.16.0\n",
      "prompt-toolkit                3.0.36\n",
      "protobuf                      4.21.12\n",
      "psutil                        5.9.4\n",
      "ptyprocess                    0.7.0\n",
      "pure-eval                     0.2.2\n",
      "pyasn1                        0.5.0\n",
      "pyasn1-modules                0.3.0\n",
      "pybind11                      2.10.4\n",
      "pycosat                       0.6.4\n",
      "pycparser                     2.21\n",
      "pycurl                        7.45.1\n",
      "Pygments                      2.14.0\n",
      "PyJWT                         2.6.0\n",
      "pyOpenSSL                     23.0.0\n",
      "pyparsing                     3.0.9\n",
      "pyrsistent                    0.19.3\n",
      "PySocks                       1.7.1\n",
      "python-dateutil               2.8.2\n",
      "python-json-logger            2.0.7\n",
      "pytz                          2022.7.1\n",
      "pytz-deprecation-shim         0.1.0.post0\n",
      "PyWavelets                    1.4.1\n",
      "PyYAML                        6.0\n",
      "pyzmq                         25.0.0\n",
      "requests                      2.28.2\n",
      "requests-oauthlib             1.3.1\n",
      "rfc3339-validator             0.1.4\n",
      "rfc3986-validator             0.1.1\n",
      "rpy2                          3.5.9\n",
      "rsa                           4.9\n",
      "ruamel.yaml                   0.17.21\n",
      "ruamel.yaml.clib              0.2.7\n",
      "scikit-image                  0.19.3\n",
      "scikit-learn                  1.2.2\n",
      "scipy                         1.10.1\n",
      "seaborn                       0.12.2\n",
      "Send2Trash                    1.8.0\n",
      "setuptools                    67.4.0\n",
      "simplegeneric                 0.8.1\n",
      "six                           1.16.0\n",
      "sniffio                       1.3.0\n",
      "sortedcontainers              2.4.0\n",
      "soupsieve                     2.3.2.post1\n",
      "SQLAlchemy                    2.0.4\n",
      "stack-data                    0.6.2\n",
      "statsmodels                   0.13.5\n",
      "sympy                         1.11.1\n",
      "tables                        3.7.0\n",
      "tabulate                      0.9.0\n",
      "tblib                         1.7.0\n",
      "tenacity                      8.2.2\n",
      "tensorboard                   2.12.3\n",
      "tensorboard-data-server       0.7.1\n",
      "tensorflow                    2.12.0\n",
      "tensorflow-estimator          2.12.0\n",
      "tensorflow-io-gcs-filesystem  0.32.0\n",
      "termcolor                     2.3.0\n",
      "terminado                     0.17.1\n",
      "threadpoolctl                 3.1.0\n",
      "tifffile                      2023.2.3\n",
      "tinycss2                      1.2.1\n",
      "tomli                         2.0.1\n",
      "toolz                         0.12.0\n",
      "torch                         2.0.1\n",
      "tornado                       6.2\n",
      "tqdm                          4.64.1\n",
      "traitlets                     5.9.0\n",
      "triton                        2.0.0\n",
      "typing_extensions             4.4.0\n",
      "tzdata                        2022.7\n",
      "tzlocal                       4.2\n",
      "unicodedata2                  15.0.0\n",
      "urllib3                       1.26.14\n",
      "wcwidth                       0.2.6\n",
      "webencodings                  0.5.1\n",
      "websocket-client              1.5.1\n",
      "Werkzeug                      2.3.6\n",
      "wheel                         0.38.4\n",
      "widgetsnbextension            4.0.5\n",
      "wordcloud                     1.9.2\n",
      "wrapt                         1.14.1\n",
      "xgboost                       1.7.5\n",
      "xlrd                          2.0.1\n",
      "y-py                          0.5.9\n",
      "ypy-websocket                 0.8.2\n",
      "zict                          2.2.0\n",
      "zipp                          3.15.0\n",
      "zstandard                     0.19.0\n"
     ]
    }
   ],
   "source": [
    "!python3 --version\n",
    "!pip3 list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcecf8c-b02d-4d3d-9e33-48b8c8897ff5",
   "metadata": {},
   "source": [
    "# Tóm tắt quá trình\n",
    "Ở phần này chúng ta sẽ lần lượt làm các công việc sau:\n",
    "* **Công việc 1**: Chia bô dữ liệu thành hai phần training data và test data nhằm đảm bảo tính công bằng trên mọi model.\n",
    "* **Công việc 2**: Chia bài toán ban đầu thành hai bài toán con là **Emoji sentiment model** và **Comment sentiment model** và giải thích lí do.\n",
    "  * **Công việc 2.1**: Xây dựng **Emoji sentiment model**. \n",
    "    * Xác định input và cách biểu diễn nó sau đó lựa chọn cách biểu diễn phù hợp.\n",
    "    * Xác định output.\n",
    "    * Tiến hành sử dụng các **Traditional Machine Learning Classifier** để đào tạo.\n",
    "    * Tối ưu hóa tham số bằng phương pháp **Grid Search**.\n",
    "    * Đánh giá model.\n",
    "    * Lưu lại model.\n",
    "  * **Công việc 2.2**: Xây dựng **Comment sentiment model**.\n",
    "    * Xác định input và cách biểu diễn nó sau đó lựa chọn cách biểu diễn phù hợp.\n",
    "    * Xác định output.\n",
    "    * Tiến hành sử dụng các **Traditional Machine Learning Classifier** để đào tạo.\n",
    "    * Tiến hành sử dụng các **Deep Learning** để đào tạo.\n",
    "    * Tối ưu hóa tham số bằng phương pháp **HyperBand**.\n",
    "    * Đánh giá model.\n",
    "    * Lưu lại model.\n",
    "* **Công việc 3**: Tổng hợp hai model **Emoji sentiment** và **Comment sentiment** để ra model cuối cùng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd76ed0f-7397-4be9-b375-683f38b79bb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85e6b05f-ede3-4f66-8f85-16a781b20d9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import modules.model as Model\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3daf2a-0261-4043-8daf-8e9858a4792c",
   "metadata": {},
   "source": [
    "## Công việc 1:\n",
    "* Phần này ta sẽ tách dữ liệu sau khi trải qua các bước tiền xử lí ở phần trước thành training data và test data. \n",
    "* Lí do ta cần thực hiện điều này là ta muốn đảm bảo công bằng cho mọi model trong quá trình đào tạo, tức chúng cùng học trên cùng một training data và được đánh giá trên cùng một test data.\n",
    "* Như ở **công việc 2** đã trình bày, ta sẽ chia dữ liệu sau tiền xử lí thành hai phần:\n",
    "  * **Phần dữ liệu chỉ chứa emoji**: phần dữ liệu này chỉ chứa các comment chứa emoji, các comment không chứa emoji ta sẽ loại bỏ.\n",
    "  * **Phần dữ liệu chỉ chứa comment**: phần dữ liệu này chính là phần dữ liệu ban đầu nhưng khác một điều toàn bộ emoji trong comment sẽ bị xóa. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2cd06fb-ccbe-4eb5-8f99-78cb6d938a82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quần giặt xong co ngắn mất 5 phân. Ne...</td>\n",
       "      <td>quần giặt xong co ngắn mất phân nên ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vải áo mặc nóng \\nCòn vải  quần dễ ...</td>\n",
       "      <td>vải áo mặc nóng còn vải quần dễ xù...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Đóng gói cẩn thận, giao đủ số lượn...</td>\n",
       "      <td>đóng gói cẩn thận giao đủ số lượng...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quần quá to mọi người ạ còn dài nx  ...</td>\n",
       "      <td>quần quá to mọi người còn dài mặc d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vải thừa hơi nhiều\\nGiao hàng nhanh .!\\...</td>\n",
       "      <td>vải thừa hơi nhiều giao hàng nhanh thủ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  \\\n",
       "0  Quần giặt xong co ngắn mất 5 phân. Ne...   \n",
       "1  Vải áo mặc nóng \\nCòn vải  quần dễ ...   \n",
       "2  Đóng gói cẩn thận, giao đủ số lượn...   \n",
       "3  Quần quá to mọi người ạ còn dài nx  ...   \n",
       "4  Vải thừa hơi nhiều\\nGiao hàng nhanh .!\\...   \n",
       "\n",
       "                                   normalize_comment  label  \n",
       "0  quần giặt xong co ngắn mất phân nên ...      0  \n",
       "1  vải áo mặc nóng còn vải quần dễ xù...      0  \n",
       "2  đóng gói cẩn thận giao đủ số lượng...      0  \n",
       "3  quần quá to mọi người còn dài mặc d...      0  \n",
       "4  vải thừa hơi nhiều giao hàng nhanh thủ...      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/normalize_reviews.csv\").fillna(\"\")[['raw_comment', 'normalize_comment', 'label']]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c177842f-8c2a-4709-9d3f-6fda7cdd1c84",
   "metadata": {},
   "source": [
    "Mã hóa các dữ liệu dạng text về cùng một dạng là **NFD**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "726540fe-87bc-4fc2-b6c2-54c00636ffb4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quần giặt xong co ngắn mất 5 phân. Ne...</td>\n",
       "      <td>quần giặt xong co ngắn mất phân nên ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vải áo mặc nóng \\nCòn vải  quần dễ ...</td>\n",
       "      <td>vải áo mặc nóng còn vải quần dễ xù...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Đóng gói cẩn thận, giao đủ số lượn...</td>\n",
       "      <td>đóng gói cẩn thận giao đủ số lượng...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quần quá to mọi người ạ còn dài nx  ...</td>\n",
       "      <td>quần quá to mọi người còn dài mặc d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vải thừa hơi nhiều\\nGiao hàng nhanh .!\\...</td>\n",
       "      <td>vải thừa hơi nhiều giao hàng nhanh thủ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  \\\n",
       "0  Quần giặt xong co ngắn mất 5 phân. Ne...   \n",
       "1  Vải áo mặc nóng \\nCòn vải  quần dễ ...   \n",
       "2  Đóng gói cẩn thận, giao đủ số lượn...   \n",
       "3  Quần quá to mọi người ạ còn dài nx  ...   \n",
       "4  Vải thừa hơi nhiều\\nGiao hàng nhanh .!\\...   \n",
       "\n",
       "                                   normalize_comment  label  \n",
       "0  quần giặt xong co ngắn mất phân nên ...      0  \n",
       "1  vải áo mặc nóng còn vải quần dễ xù...      0  \n",
       "2  đóng gói cẩn thận giao đủ số lượng...      0  \n",
       "3  quần quá to mọi người còn dài mặc d...      0  \n",
       "4  vải thừa hơi nhiều giao hàng nhanh thủ...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = Model.textNFxformat(data, ['raw_comment', 'normalize_comment'], 'NFD')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2036a2c-12b8-46a5-b8f3-851f2ca682d4",
   "metadata": {},
   "source": [
    "Các vectorizer object của **sklearn** mặc định chúng sẽ xóa toàn bộ các **punctuation** [kí tự đặc biệt] trong input truyền vào. Như vậy các emoji của ta sẽ bị xóa toàn bộ khi transform vectorizing. Như vậy, ta sẽ không lưu chúng dưới dạng các punctuation mà dùng decode của chúng - ta sẽ tạo một feature `emoji_decode` để lưu chúng.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b907aa04-640f-4543-a715-777ca8016882",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>emoji_decode</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quần giặt xong co ngắn mất 5 phân. Ne...</td>\n",
       "      <td>quần giặt xong co ngắn mất phân nên ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vải áo mặc nóng \\nCòn vải  quần dễ ...</td>\n",
       "      <td>vải áo mặc nóng còn vải quần dễ xù...</td>\n",
       "      <td>heart heart</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Đóng gói cẩn thận, giao đủ số lượn...</td>\n",
       "      <td>đóng gói cẩn thận giao đủ số lượng...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quần quá to mọi người ạ còn dài nx  ...</td>\n",
       "      <td>quần quá to mọi người còn dài mặc d...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vải thừa hơi nhiều\\nGiao hàng nhanh .!\\...</td>\n",
       "      <td>vải thừa hơi nhiều giao hàng nhanh thủ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  \\\n",
       "0  Quần giặt xong co ngắn mất 5 phân. Ne...   \n",
       "1  Vải áo mặc nóng \\nCòn vải  quần dễ ...   \n",
       "2  Đóng gói cẩn thận, giao đủ số lượn...   \n",
       "3  Quần quá to mọi người ạ còn dài nx  ...   \n",
       "4  Vải thừa hơi nhiều\\nGiao hàng nhanh .!\\...   \n",
       "\n",
       "                                   normalize_comment emoji_decode  label  \n",
       "0  quần giặt xong co ngắn mất phân nên ...                   0  \n",
       "1  vải áo mặc nóng còn vải quần dễ xù...  heart heart      0  \n",
       "2  đóng gói cẩn thận giao đủ số lượng...                   0  \n",
       "3  quần quá to mọi người còn dài mặc d...                   0  \n",
       "4  vải thừa hơi nhiều giao hàng nhanh thủ...                   0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['emoji_decode'] = data['raw_comment'].apply(lambda s: Model.expandEmojisDecode(s))\n",
    "data = data[['raw_comment', 'normalize_comment', 'emoji_decode', 'label']]\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52226b79-9847-4339-9c6a-4c0fb6154e54",
   "metadata": {
    "tags": []
   },
   "source": [
    "Tiến hành chọn các mẫu có feature `emoji_decode` không phải là chuổi rỗng và lưu vào biến `emoji_data`. Các mẫu trong biến này sẽ được dùng để xây dựng một **Emoji sentiment model**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4df9e826-e63f-4d9a-971f-5263b7fdbaf8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>emoji_decode</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Vải áo mặc nóng \\nCòn vải  quần dễ ...</td>\n",
       "      <td>vải áo mặc nóng còn vải quần dễ xù...</td>\n",
       "      <td>heart heart</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Áo vải mỏng. Chất quần áo nóng. Mình...</td>\n",
       "      <td>áo vải mỏng chất quần áo nóng đặt s...</td>\n",
       "      <td>slightly_smiling_face</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hơi thất vọng 😔 m tưởng là cuộn to a...</td>\n",
       "      <td>hơi thất vọng tưởng là cuộn to ai de...</td>\n",
       "      <td>frowning_face pensive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sản phẩm chỉ là áo form rộng thường...</td>\n",
       "      <td>sản phẩm chỉ là áo form rộng thường...</td>\n",
       "      <td>disappointed disappointed disappointed</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K giống trong ảnh, vải xấu 😡😡😡😡😡😡</td>\n",
       "      <td>không giống trong ảnh vải xấu</td>\n",
       "      <td>pout pout pout pout pout pout</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  \\\n",
       "0  Vải áo mặc nóng \\nCòn vải  quần dễ ...   \n",
       "1  Áo vải mỏng. Chất quần áo nóng. Mình...   \n",
       "2  Hơi thất vọng 😔 m tưởng là cuộn to a...   \n",
       "3  Sản phẩm chỉ là áo form rộng thường...   \n",
       "4            K giống trong ảnh, vải xấu 😡😡😡😡😡😡   \n",
       "\n",
       "                                   normalize_comment  \\\n",
       "0  vải áo mặc nóng còn vải quần dễ xù...   \n",
       "1  áo vải mỏng chất quần áo nóng đặt s...   \n",
       "2  hơi thất vọng tưởng là cuộn to ai de...   \n",
       "3  sản phẩm chỉ là áo form rộng thường...   \n",
       "4               không giống trong ảnh vải xấu   \n",
       "\n",
       "                             emoji_decode  label  \n",
       "0                             heart heart      0  \n",
       "1                   slightly_smiling_face      0  \n",
       "2                   frowning_face pensive      0  \n",
       "3  disappointed disappointed disappointed      0  \n",
       "4           pout pout pout pout pout pout      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emoji_data = data[data['emoji_decode'] != \"\"].reset_index(drop=True)\n",
    "\n",
    "emoji_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5c50ea-5770-41b7-88ef-6934fabe0b32",
   "metadata": {},
   "source": [
    "Giờ thì ta sẽ tiến hành chia `emoji_data` thành training data và test data với size của test data là 20%, sau đó ta lưu chúng dưới dạng file **.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "235c75f4-400e-4023-a79c-e47bdb4ba487",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📢 Your dataset has saved at ./data/emoji_data.\n"
     ]
    }
   ],
   "source": [
    "Model.dataSplitSaved(emoji_data, 0.2, \"./data/emoji_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4a0683-8ad8-4f6e-9b61-e32f27751791",
   "metadata": {},
   "source": [
    "Bây giờ ta cần chuẩn bị training data và test data cho **Comment sentiment model**, ta cũng sẽ chia tập dữ liệu sau tiền xử lí thành hai phần training data và test data với test data chiếm 20% dữ liệu sau tiền xử lí. Cuối cùng ta cũng sẽ lưu hai tập training data và test data này dưới dạng file **.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6c805dd-8460-449e-8d37-699336b0885d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_comment</th>\n",
       "      <th>normalize_comment</th>\n",
       "      <th>emoji_decode</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Quần giặt xong co ngắn mất 5 phân. Ne...</td>\n",
       "      <td>quần giặt xong co ngắn mất phân nên ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Vải áo mặc nóng \\nCòn vải  quần dễ ...</td>\n",
       "      <td>vải áo mặc nóng còn vải quần dễ xù...</td>\n",
       "      <td>heart heart</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Đóng gói cẩn thận, giao đủ số lượn...</td>\n",
       "      <td>đóng gói cẩn thận giao đủ số lượng...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quần quá to mọi người ạ còn dài nx  ...</td>\n",
       "      <td>quần quá to mọi người còn dài mặc d...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Vải thừa hơi nhiều\\nGiao hàng nhanh .!\\...</td>\n",
       "      <td>vải thừa hơi nhiều giao hàng nhanh thủ...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         raw_comment  \\\n",
       "0  Quần giặt xong co ngắn mất 5 phân. Ne...   \n",
       "1  Vải áo mặc nóng \\nCòn vải  quần dễ ...   \n",
       "2  Đóng gói cẩn thận, giao đủ số lượn...   \n",
       "3  Quần quá to mọi người ạ còn dài nx  ...   \n",
       "4  Vải thừa hơi nhiều\\nGiao hàng nhanh .!\\...   \n",
       "\n",
       "                                   normalize_comment emoji_decode  label  \n",
       "0  quần giặt xong co ngắn mất phân nên ...                   0  \n",
       "1  vải áo mặc nóng còn vải quần dễ xù...  heart heart      0  \n",
       "2  đóng gói cẩn thận giao đủ số lượng...                   0  \n",
       "3  quần quá to mọi người còn dài mặc d...                   0  \n",
       "4  vải thừa hơi nhiều giao hàng nhanh thủ...                   0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e20d732-893f-4ba8-bb66-cc38a1294129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📢 Your dataset has saved at ./data/data.\n"
     ]
    }
   ],
   "source": [
    "Model.dataSplitSaved(data, 0.2, \"./data/data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af6aae-6c28-481e-833d-d1d04eae712f",
   "metadata": {},
   "source": [
    "## Công việc 2:\n",
    "* Ở phần này, nhóm sẽ trình bày về các vấn đề sau:\n",
    "  * **Vấn đề 1**: Lựa chọn thuật toán tương ứng lần lượt cho hai model và lí giải.\n",
    "  * **Vấn đề 2**: Lựa chọn kĩ thuật đánh giá. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4847f95a-1395-4197-af47-693318c5a41b",
   "metadata": {},
   "source": [
    "### Vấn đề 1:\n",
    "* Bài toán của chúng ta là NLP - như vậy thì dữ liệu sẽ khiến cho chúng ta khó hiểu hơn về dữ liệu. Nhưng theo những gì nhóm đã được học ở những môn trước thì nhóm có hi vọng cao vào hai thuật toán là **Logistic Regression** và **Support Vector Machine**. Tuy nhiên nhóm vẫn sẽ áp dụng các model classification khác như Naive Bayes, Random Forest,... vì khả năng cao chúng có thể đại diện tốt cho dataset của chúng ta.\n",
    "\n",
    "#### Logistic Regession:\n",
    "* Ở phần đào tạo mô hình sau này, nhóm sẽ ưu tiên sử dụng thuật toán này trên các `solver` khác nhau như `newton-cg`, `lbfgs`, `liblinear`. Đây là một sự ưu tiên cho thuật toán này vì nhóm nghĩ nó hiệu quả vì:\n",
    "  * Bài toán của chúng ta là **binary classification** và **Logistic Regression** thường được coi là thuật toán cơ bản nhất cho các bài toán dạng này.\n",
    "  * Thuật toán **Logistic Regression** có thời gian thực thi nhanh và cách cài đặt đơn giản, các **hyper-parameter** không nhiều nên dễ dàng thực hiện kĩ thuật **Tunning Hyper-Parameters**.\n",
    "  * Đối với **Emoji sentiment model**, thực chất số lượng emoji mà người dùng hay dùng không nhiều, số emoji trong một comment cũng không nhiều $\\Rightarrow$ Khiến cho dữ liệu đào tạo đơn giản và dễ hiểu nên **Logistic Regression** rất phù hợp với các dataset đơn giản như vậy đồng thời sẽ cho ra độ chính xác cao.\n",
    "  * Với **Comment sentiment model** - dữ liệu phức tạp hơn nhưng chúng ta cũng nên kì vọng là thuật toán này sẽ hoạt động tốt.\n",
    "  \n",
    "#### Support Vector Machine\n",
    "* Do nhóm nghĩ đây là một thuật toán hiệu quả, nên nhóm cũng sẽ có chút ưu tiên cho thuật toán bày bằng cách triển khai nó trên nhiều `kernel` khác nhau như `linear`, `poly`, `rbf`, `sigmoid`. Lí do nhóm ưu tiên thuật toán này là vì:\n",
    "  * Với các dữ liệu mà ta khó có cái nhìn tổng quan hoặc ý tưởng thì SVM là một mô hình khá tốt để ta tiến hành đào tạo vì nó linh hoạt - có thể dùng cho hai bài toán là **regression** và **classification** thậm chí là cho cả các bài toán **clustering**.\n",
    "  * Nó hoạt động tốt trên dữ liệu phức tạp mà với dữ liệu text thì text hay được biểu diễn dưới dạng vector.\n",
    "  * Với các bài toán phân lớp, nó sử dụng các `kernel` để đưa input đầu vào vào một không gian có nhiều chiều hơn ngoài ra còn cố gắng tối đa hóa khoảng cách giữa **sepertating hyperplan** với các **super vectors**.<br>\n",
    "    ![](./images/10.png)\n",
    "  * Hoạt động hiệu quả trên bài toán phân loại văn bản, dữ liệu phi cấu trúc và nhiều chiều.\n",
    "  * Ngoài ra, sức mạnh của thuật toán này chính là dựa trên các `kernel` mà ta lựa chọn, tuy nhiên để chọn ra `kernel` tốt không dễ dàng nên ta thường vét cạn, nhưng nếu dữ liệu quá lớn thì không nên vì thời gian đào tạo của thuật toán này lâu, có thể nói ngang ngữa với các **Deep Neural Network**.\n",
    "\n",
    "#### Deep Neural Netword\n",
    "* Các thuật toán thuộc nhóm DNN sẽ được trình bày sau. Nhóm sẽ tập trung trình bày vào LSTM vì đây là model hoạt động tốt nhất trên dataset của nhóm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9ba9a0-293e-4d2c-ab36-c35d37614d4b",
   "metadata": {},
   "source": [
    "### Vấn đề 2:\n",
    "![](./images/11.png)\n",
    "* Chúng ta sẽ sử dụng hai độ đo phổ biến nhất dành cho các classification model là:\n",
    "  * **Accuracy**: dùng để đánh giá độ chính xác của model trên **TN** và **TP**.\n",
    "  * **ROC-AUC**: accuracy sẽ không chính xác nếu như số lượng mẫu giữa các class bị mất cân bằng nên ROC-AUC sẽ giúp ta kiểm tra việc xem có một class nào nổi trội hơn so với class còn lại không."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e64adf11-43e0-44c8-8420-335363aab6db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
